% Encoding: UTF-8

@Article{8054694,
  author   = {T. {O’Shea} and J. {Hoydis}},
  journal  = {IEEE Transactions on Cognitive Communications and Networking},
  title    = {An Introduction to Deep Learning for the Physical Layer},
  year     = {2017},
  issn     = {2332-7731},
  month    = {Dec},
  number   = {4},
  pages    = {563-575},
  volume   = {3},
  abstract = {We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation.},
  doi      = {10.1109/TCCN.2017.2758370},
  keywords = {computer networks;convolution;feedforward neural nets;learning (artificial intelligence);open systems;optimisation;receivers;deep learning;physical layer;communications system design;end-to-end reconstruction task;receiver components;multiple transmitters;radio transformer networks;expert domain knowledge;machine learning model;convolutional neural networks;autoencoder;joint optimisation;transmitter components;modulation classification;Artificial neural networks;Physical layer;Communication systems;Receivers;Modulation;Radio transmitters;Machine learning;Machine learning;deep learning;physical layer;digital communications;modulation;radio communication;cognitive radio},
}

@Article{7103337,
  author   = {J. {Tang} and C. {Deng} and G. {Huang}},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Extreme Learning Machine for Multilayer Perceptron},
  year     = {2016},
  issn     = {2162-2388},
  month    = {April},
  number   = {4},
  pages    = {809-821},
  volume   = {27},
  abstract = {Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via ℓ1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.},
  doi      = {10.1109/TNNLS.2015.2424995},
  keywords = {feedforward neural nets;learning (artificial intelligence);multilayer perceptrons;pattern classification;extreme learning machine;multilayer perceptron;learning algorithm;generalized single hidden layer feedforward neural networks;feature learning;ELM-based hierarchical learning framework;self-taught feature extraction;supervised feature classification;random initialized hidden weights;unsupervised multilayer encoding;ELM-based sparse autoencoder;feature representations;ELM random feature mapping;hierarchically encoded outputs;decision making;learning speed;greedy layerwise training;deep learning;DL;hierarchical learning methods;computer vision;Feature extraction;Training;Nonhomogeneous media;Optimization;Least squares approximations;Artificial neural networks;Deep learning (DL);deep neural network (DNN);extreme learning machine (ELM);multilayer perceptron (MLP);random feature mapping.;Deep learning (DL);deep neural network (DNN);extreme learning machine (ELM);multilayer perceptron (MLP);random feature mapping},
}

@InProceedings{9013510,
  author    = {M. H. {Jespersen} and M. {Pajovic} and T. {Koike-Akino} and Y. {Wang} and P. {Popovski} and P. V. {Orlik}},
  booktitle = {2019 IEEE Global Communications Conference (GLOBECOM)},
  title     = {Deep Learning for Synchronization and Channel Estimation in NB-IoT Random Access Channel},
  year      = {2019},
  month     = {Dec},
  pages     = {1-7},
  abstract  = {The central challenge in supporting massive IoT connectivity is the uncoordinated, random access by sporadically active devices. The random access protocol and activity detection have been widely studied, while the auxiliary procedures, such as synchronization, channel estimation and equalization, have received much less attention. However, once the protocol is fixed, the access performance can only be improved by a more effective receiver, through more accurate execution of the auxiliary procedures. This motivates the pursuit of joint synchronization and channel estimation, rather than the traditional approach of handling them separately. The prohibitive complexity of the conventional analytical solutions leads us to employ the tools of deep learning in this paper. Specifically, the proposed method is applied to the random access protocol of Narrowband IoT (NB-IoT), preserving its standard preamble structure. We obtain excellent performance in estimating Time-of-Arrival (ToA), Carrier-Frequency Offset (CFO), channel gain and collision multiplicity from a received mixture of transmissions. The proposed estimator achieves a ToA Root-Mean-Square Error (RMSE) of 0.99 us and a CFO RMSE of 1.61 Hz at 10 dB Signal-to-Noise Ratio (SNR), whereas a conventional estimator using two cascaded stages have RMSEs of 15.85 us and 8.05 Hz, respectively.},
  doi       = {10.1109/GLOBECOM38437.2019.9013510},
  issn      = {2576-6813},
  keywords  = {Channel estimation;Base stations;Machine learning;Standards;Signal to noise ratio;Estimation;Uplink},
}

@Misc{hershey2014deep,
  author        = {John R. Hershey and Jonathan Le Roux and Felix Weninger},
  title         = {Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures},
  year          = {2014},
  archiveprefix = {arXiv},
  eprint        = {1409.2574},
  primaryclass  = {cs.LG},
}

@InProceedings{8761999,
  author    = {S. {Xue} and Y. {Ma} and A. {Li} and N. {Yi} and R. {Tafazolli}},
  booktitle = {ICC 2019 - 2019 IEEE International Conference on Communications (ICC)},
  title     = {On Unsupervised Deep Learning Solutions for Coherent MU-SIMO Detection in Fading Channels},
  year      = {2019},
  month     = {May},
  pages     = {1-6},
  abstract  = {In this paper, unsupervised deep learning solutions for multiuser single-input multiple-output (MU-SIMO) coherent detection are extensively investigated. According to the ways of utilizing the channel state information at the receiver side (CSIR), deep learning solutions are divided into two groups. One group is called equalization and learning, which utilizes the CSIR for channel equalization and then employ deep learning for multiuser detection (MUD). The other is called direct learning, which directly feeds the CSIR, together with the received signal, into deep neural networks (DNN) to conduct the MUD. It is found that the direct learning solutions outperform the equalization-and-learning solutions due to their better exploitation of the sequence detection gain. On the other hand, the direct learning solutions are not scalable to the size of SIMO networks, as current DNN architectures cannot efficiently handle many co-channel interferences. Motivated by this observation, we propose a novel direct learning approach, which can combine the merits of feedforward DNN and parallel interference cancellation. It is shown that the proposed approach trades off the complexity for the learning scalability, and the complexity can be managed due to the parallel network architecture.},
  doi       = {10.1109/ICC.2019.8761999},
  issn      = {1938-1883},
  keywords  = {fading channels;interference suppression;multiuser channels;neural nets;SIMO communication;supervised learning;coherent MU-SIMO detection;fading channels;unsupervised deep learning solutions;multiuser single-input multiple-output coherent detection;channel state information;CSIR;channel equalization;multiuser detection;deep neural networks;direct learning solutions;sequence detection gain;direct learning approach;learning scalability;equalization-and-learning solutions;Deep learning;Fading channels;Receivers;MIMO communication;Training data;Complexity theory},
}

@Article{Huang2006,
  author   = {Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew},
  journal  = {Neurocomputing},
  title    = {Extreme learning machine: Theory and applications},
  year     = {2006},
  issn     = {0925-2312},
  note     = {Neural Networks},
  number   = {1},
  pages    = {489 - 501},
  volume   = {70},
  abstract = {It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.11For the preliminary idea of the ELM algorithm, refer to “Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks”, Proceedings of International Joint Conference on Neural Networks (IJCNN2004), Budapest, Hungary, 25–29 July, 2004.},
  doi      = {https://doi.org/10.1016/j.neucom.2005.12.126},
  keywords = {Feedforward neural networks, Back-propagation algorithm, Extreme learning machine, Support vector machine, Real-time learning, Random node},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231206000385},
}

@Article{DBLP:journals/corr/OSheaC16,
  author        = {Timothy J. O'Shea and Johnathan Corgan},
  journal       = {CoRR},
  title         = {Convolutional Radio Modulation Recognition Networks},
  year          = {2016},
  volume        = {abs/1602.04105},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/OSheaC16.bib},
  eprint        = {1602.04105},
  timestamp     = {Mon, 13 Aug 2018 16:46:04 +0200},
  url           = {http://arxiv.org/abs/1602.04105},
}

@Online{TegraX1,
  author = {NVIDIA Corporation},
  title  = {NVIDIA TURING GPU ARCHITECTURE Graphics Reinvented},
  url    = {https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf},
  year   = {2018},
}

@Manual{cudatfortegra,
  title  = {Cuda Toolkit Documentation},
  author = {NVDIA Corporation},
  url    = {https://docs.nvidia.com/cuda/cuda-for-tegra-appnote/index.html#memory-selection},
}

@Article{grcon,
  author   = {Timothy O'Shea and Nathan West},
  journal  = {Proceedings of the GNU Radio Conference},
  title    = {Radio Machine Learning Dataset Generation with GNU Radio},
  year     = {2016},
  number   = {1},
  volume   = {1},
  abstract = {This paper surveys emerging applications of Machine Learning (ML) to the Radio Signal Processing domain.  Provides some brief background on enabling methods and discusses some of the potential advancements for the field.  It discusses the critical importance of good datasets for model learning, testing, and evaluation and introduces several public open source synthetic datasets for various radio machine learning tasks.  These are intended to provide a robust common baselines for those working in the field and to provide a benchmark measure against which many techniques can be rapidly evaluated and compared.},
  url      = {https://pubs.gnuradio.org/index.php/grcon/article/view/11},
}

@Article{8466371,
  author   = {S. {Riyaz} and K. {Sankhe} and S. {Ioannidis} and K. {Chowdhury}},
  journal  = {IEEE Communications Magazine},
  title    = {Deep Learning Convolutional Neural Networks for Radio Identification},
  year     = {2018},
  issn     = {1558-1896},
  month    = {Sep.},
  number   = {9},
  pages    = {146-152},
  volume   = {56},
  abstract = {Advances in software defined radio (SDR) technology allow unprecedented control on the entire processing chain, allowing modification of each functional block as well as sampling the changes in the input waveform. This article describes a method for uniquely identifying a specific radio among nominally similar devices using a combination of SDR sensing capability and machine learning (ML) techniques. The key benefit of this approach is that ML operates on raw I/Q samples and distinguishes devices using only the transmitter hardware-induced signal modifications that serve as a unique signature for a particular device. No higher-level decoding, feature engineering, or protocol knowledge is needed, further mitigating challenges of ID spoofing and coexistence of multiple protocols in a shared spectrum. The contributions of the article are as follows: (i) The operational blocks in a typical wireless communications processing chain are modified in a simulation study to demonstrate RF impairments, which we exploit. (ii) Using an over-the-air dataset compiled from an experimental testbed of SDRs, an optimized deep convolutional neural network architecture is proposed, and results are quantitatively compared with alternate techniques such as support vector machines and logistic regression. (iii) Research challenges for increasing the robustness of the approach, as well as the parallel processing needs for efficient training, are described. Our work demonstrates up to 90-99 percent experimental accuracy at transmitter- receiver distances varying between 2-50 ft over a noisy, multi-path wireless channel.},
  doi      = {10.1109/MCOM.2018.1800153},
  keywords = {learning (artificial intelligence);multipath channels;neural nets;software radio;telecommunication computing;wireless channels;ID spoofing;noisy multipath wireless channel;parallel processing needs;support vector machines;optimized deep convolutional neural network architecture;typical wireless communications processing chain;operational blocks;shared spectrum;unique signature;transmitter hardware-induced signal modifications;input waveform;functional block;SDR;software defined radio technology;radio identification;convolutional neural networks;Machine learning;Wireless communication;Radio frequency;Transmitters;Phase noise;Object recognition;Radio communication},
}

@Article{Borgerding2017,
  author  = {Borgerding, Mark and Schniter, Philip and Rangan, Sundeep},
  journal = {IEEE Transactions on Signal Processing},
  title   = {AMP-Inspired Deep Networks for Sparse Linear Inverse Problems},
  year    = {2017},
  month   = {05},
  pages   = {1-1},
  volume  = {PP},
  doi     = {10.1109/TSP.2017.2708040},
}

@Article{Folorunso2019,
  author = {Folorunso, Oladipo and Ojo, Adedayo},
  title  = {Channel Estimation In MIMO -OFDM Wireless Communication Systems},
  year   = {2019},
  month  = {06},
}

@Misc{uhrig2017sparsity,
  author        = {Jonas Uhrig and Nick Schneider and Lukas Schneider and Uwe Franke and Thomas Brox and Andreas Geiger},
  title         = {Sparsity Invariant CNNs},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1708.06500},
  primaryclass  = {cs.CV},
}

@InProceedings{8088621,
  author    = {I. {Ahmad} and T. {Kumar} and M. {Liyanage} and J. {Okwuibe} and M. {Ylianttila} and A. {Gurtov}},
  booktitle = {2017 IEEE Conference on Standards for Communications and Networking (CSCN)},
  title     = {5G security: Analysis of threats and solutions},
  year      = {2017},
  month     = {Sep.},
  pages     = {193-199},
  abstract  = {5G will provide broadband access everywhere, entertain higher user mobility, and enable connectivity of massive number of devices (e.g. Internet of Things (IoT)) in an ultrareliable and affordable way. The main technological enablers such as cloud computing, Software Defined Networking (SDN) and Network Function Virtualization (NFV) are maturing towards their use in 5G. However, there are pressing security challenges in these technologies besides the growing concerns for user privacy. In this paper, we provide an overview of the security challenges in these technologies and the issues of privacy in 5G. Furthermore, we present security solutions to these challenges and future directions for secure 5G systems.},
  doi       = {10.1109/CSCN.2017.8088621},
  keywords  = {5G mobile communication;data privacy;security of data;telecommunication security;security challenges;user privacy;security solutions;secure 5G systems;5G security;threats analysis;Security;5G mobile communication;Cloud computing;Mobile computing;Privacy;Control systems;Security;5G Security;SDN;NFV;Cloud;Privacy;Communication Channels},
}

@InProceedings{7360505,
  author    = {A. S. {Oluwole} and V. M. {Srivastava}},
  booktitle = {2015 International Conference on Cyberspace (CYBER-Abuja)},
  title     = {Modeling of RF security system using smart antennas},
  year      = {2015},
  month     = {Nov},
  pages     = {118-122},
  abstract  = {This work establishes a state-of-the-art protective measure on how the smart antennas can be used effectively to curtail the activities of hackers/intruders on radio frequency signals. Hackers can scan confidential information/data belonging to organization, law enforcement and even interception of radio frequencies signals to the public usage. In this analysis, three antenna elements array have been used. (i) The first antenna elements was used for the transmission/reception (transceiver) of radio frequency signal. This transceiver also acts for remotely transmitting information signal virtual to mobile station. (ii) The two antenna elements at the mobile station is being used as descrambler against any illegitimate activities. Some of the imperative securities challenges covered in this work are secrecy, authentication, privacy, and attacks. In the choice of frequency bandwidth for the transmission of signal, IEEE standard 802.11 designed for wireless local area network system had been maintained.},
  doi       = {10.1109/CYBER-Abuja.2015.7360505},
  keywords  = {antenna arrays;computer network security;cryptography;data privacy;direction-of-arrival estimation;mobile antennas;mobile radio;radio transceivers;wireless LAN;smart antennas;RF security system model;hacker activities;intruder activities;radio frequency signal interception;confidential information scan;confidential data scan;wireless local area network system;IEEE standard 802.11 design;data attacks;data privacy;data authentication;data secrecy;illegitimate activities;mobile station;information signal remote transmission;radio frequency signal transceiver;radio frequency signal transmission-reception;antenna element array;law enforcement;organization;Antenna arrays;Transceivers;Transmitting antennas;Radio frequency;Arrays;Mobile antennas;Antenna arrays;Internet of things;Network security;Radio frequency;Signals;Smart Antennas},
}

@Manual{ad9371,
  title  = {Data Sheet AD9371},
  author = {Anologue_Devices},
  year   = {2017 (accessed September 21, 2020)},
  url    = {https://developer.arm.com/architectures/instruction-sets/simd-isas/neon/neon-programmers-guide-for-armv8-a/optimizing-c-code-with-neon-intrinsics/single-page},
}

@InProceedings{7345407,
  author    = {P. {Schneider} and G. {Horn}},
  booktitle = {2015 IEEE Trustcom/BigDataSE/ISPA},
  title     = {Towards 5G Security},
  year      = {2015},
  month     = {Aug},
  pages     = {1165-1170},
  volume    = {1},
  abstract  = {This paper discusses potential security requirements and mechanisms for 5G mobile networks. It does not intend to do so exhaustively, but rather aims at initiating and spurring the work towards a 5G security architecture.},
  doi       = {10.1109/Trustcom.2015.499},
  keywords  = {5G mobile communication;computer network security;5G mobile network security architecture;potential security requirement;potential security mechanism;5G mobile communication;Authentication;3G mobile communication;Mobile computing;Protocols;security;5G;mobile network protection},
}

@InProceedings{9083731,
  author    = {M. {Jinsong} and M. {Yamin}},
  booktitle = {2020 7th International Conference on Computing for Sustainable Global Development (INDIACom)},
  title     = {5G Network and Security},
  year      = {2020},
  pages     = {249-254},
}

@InProceedings{9139835,
  author    = {D. {Yan} and W. {Wang} and X. {Chu}},
  booktitle = {2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  title     = {Demystifying Tensor Cores to Optimize Half-Precision Matrix Multiply},
  year      = {2020},
  month     = {May},
  pages     = {634-643},
  abstract  = {Half-precision matrix multiply has played a key role in the training of deep learning models. The newly designed Nvidia Tensor Cores offer the native instructions for half-precision small matrix multiply, based on which Half-precision General Matrix Multiply (HGEMM) routines are developed and can be accessed through high-level APIs. In this paper, we, for the first time, demystify how Tensor Cores on NVIDIA Turing architecture work in great details, including the instructions used, the registers and data layout required, as well as the throughput and latency of Tensor Core operations. We further benchmark the memory system of Turing GPUs and conduct quantitative analysis of the performance. Our analysis shows that the bandwidth of DRAM, L2 cache and shared memory is the new bottleneck for HGEMM, whose performance is previously believed to be bound by computation. Based on our newly discovered features of Tensor Cores, we apply a series of optimization techniques on the Tensor Core-based HGEMM, including blocking size optimization, data layout redesign, data prefetching, and instruction scheduling. Extensive evaluation results show that our optimized HGEMM routine achieves an average of 1.73× and 1.46× speedup over the native implementation of cuBLAS 10.1 on NVIDIA Turing RTX2070 and T4 GPUs, respectively. The code of our implementation is written in native hardware assembly (SASS).},
  doi       = {10.1109/IPDPS47924.2020.00071},
  issn      = {1530-2075},
  keywords  = {application program interfaces;cache storage;computer graphic equipment;coprocessors;DRAM chips;learning (artificial intelligence);matrix multiplication;optimisation;shared memory systems;Turing machines;Half-precision General Matrix Multiply routines;NVIDIA Turing architecture work;optimized HGEMM routine;NVIDIA Turing RTX2070;demystifying tensor cores;half-precision matrix multiply optimization;tensor core operations;tensor core-based HGEMM;memory system;Turing GPU;DRAM;L2 cache;Nvidia Tensor Cores;shared memory;optimization techniques;blocking size optimization;data layout redesign;hardware assembly;Tensile stress;Hidden Markov models;Graphics processing units;Registers;Benchmark testing;Layout;C++ languages;GEMM;GPU;Tensor Core;Half-precision},
}

@Article{7384530,
  author   = {S. {Park} and J. {Park} and K. {Bong} and D. {Shin} and J. {Lee} and S. {Choi} and H. {Yoo}},
  journal  = {IEEE Transactions on Biomedical Circuits and Systems},
  title    = {An Energy-Efficient and Scalable Deep Learning/Inference Processor With Tetra-Parallel MIMD Architecture for Big Data Applications},
  year     = {2015},
  issn     = {1940-9990},
  month    = {Dec},
  number   = {6},
  pages    = {838-848},
  volume   = {9},
  abstract = {Deep Learning algorithm is widely used for various pattern recognition applications such as text recognition, object recognition and action recognition because of its best-in-class recognition accuracy compared to hand-crafted algorithm and shallow learning based algorithms. Long learning time caused by its complex structure, however, limits its usage only in high-cost servers or many-core GPU platforms so far. On the other hand, the demand on customized pattern recognition within personal devices will grow gradually as more deep learning applications will be developed. This paper presents a SoC implementation to enable deep learning applications to run with low cost platforms such as mobile or portable devices. Different from conventional works which have adopted massively-parallel architecture, this work adopts task-flexible architecture and exploits multiple parallelism to cover complex functions of convolutional deep belief network which is one of popular deep learning/inference algorithms. In this paper, we implement the most energy-efficient deep learning and inference processor for wearable system. The implemented 2.5 mm ×4.0 mm deep learning/inference processor is fabricated using 65 nm 8-metal CMOS technology for a battery-powered platform with real-time deep inference and deep learning operation. It consumes 185 mW average power, and 213.1 mW peak power at 200 MHz operating frequency and 1.2 V supply voltage. It achieves 411.3 GOPS peak performance and 1.93 TOPS/W energy efficiency, which is 2.07× higher than the state-of-the-art.},
  doi      = {10.1109/TBCAS.2015.2504563},
  keywords = {belief networks;Big Data;biomedical engineering;learning (artificial intelligence);program processors;system-on-chip;scalable deep learning-inference processor;tetraparallel MIMD architecture;Big data applications;deep Learning algorithm;pattern recognition applications;text recognition;object recognition;action recognition;best-in-class recognition accuracy;hand-crafted algorithm;shallow learning based algorithms;GPU platforms;SoC implementation;mobile device;portable device;energy-efficient deep learning;wearable system;CMOS technology;battery-powered platform;Machine learning;Big data;Neurons;Convolution;Pattern recognition;Graphics processing units;Parallel architectures;Convolutional deep belief networks;deep inference;deep learning;fog computing;semi-supervised learning;Algorithms;Equipment and Supplies;Learning;Pattern Recognition, Physiological;Signal Processing, Computer-Assisted;Software},
}

@Misc{haider2020artificial,
  author        = {Noman Haider and Muhammad Zeeshan Baig and Muhammad Imran},
  title         = {Artificial Intelligence and Machine Learning in 5G Network Security: Opportunities, advantages, and future research trends},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2007.04490},
  primaryclass  = {cs.CR},
}

@Misc{shi2019deep,
  author        = {Yi Shi and Kemal Davaslioglu and Yalin E. Sagduyu and William C. Headley and Michael Fowler and Gilbert Green},
  title         = {Deep Learning for RF Signal Classification in Unknown and Dynamic Spectrum Environments},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1909.11800},
  primaryclass  = {cs.NI},
}

@Misc{ramjee2019fast,
  author        = {Sharan Ramjee and Shengtai Ju and Diyu Yang and Xiaoyu Liu and Aly El Gamal and Yonina C. Eldar},
  title         = {Fast Deep Learning for Automatic Modulation Classification},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1901.05850},
  primaryclass  = {eess.SP},
}

@Article{Hubert2018,
  author   = {Hubert, Mia and Debruyne, Michiel and Rousseeuw, Peter J.},
  journal  = {WIREs Computational Statistics},
  title    = {Minimum covariance determinant and extensions},
  year     = {2018},
  number   = {3},
  pages    = {e1421},
  volume   = {10},
  abstract = {The minimum covariance determinant (MCD) method is a highly robust estimator of multivariate location and scatter, for which a fast algorithm is available. Since estimating the covariance matrix is the cornerstone of many multivariate statistical methods, the MCD is an important building block when developing robust multivariate techniques. It also serves as a convenient and efficient tool for outlier detection. The MCD estimator is reviewed, along with its main properties such as affine equivariance, breakdown value, and influence function. We discuss its computation, and list applications and extensions of the MCD in applied and methodological multivariate statistics. Two recent extensions of the MCD are described. The first one is a fast deterministic algorithm which inherits the robustness of the MCD while being almost affine equivariant. The second is tailored to high-dimensional data, possibly with more dimensions than cases, and incorporates regularization to prevent singular matrices. This article is categorized under: Statistical and Graphical Methods of Data Analysis > Multivariate Analysis Statistical and Graphical Methods of Data Analysis > Robust Methods Statistical Learning and Exploratory Methods of the Data Sciences > Knowledge Discovery},
  doi      = {10.1002/wics.1421},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1421},
  keywords = {algorithms, covariance matrix, multivariate statistics, outlier detection, robust estimation},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1421},
}

@Misc{klambauer2017selfnormalizing,
  author        = {Günter Klambauer and Thomas Unterthiner and Andreas Mayr and Sepp Hochreiter},
  title         = {Self-Normalizing Neural Networks},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1706.02515},
  primaryclass  = {cs.LG},
}

@Misc{verbraeken2019survey,
  author        = {Joost Verbraeken and Matthijs Wolting and Jonathan Katzy and Jeroen Kloppenburg and Tim Verbelen and Jan S. Rellermeyer},
  title         = {A Survey on Distributed Machine Learning},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1912.09789},
  primaryclass  = {cs.LG},
}

@Misc{kirkpatrick2017overcoming,
  author        = {James Kirkpatrick and Razvan Pascanu and Neil Rabinowitz and Joel Veness and Guillaume Desjardins and Andrei A. Rusu and Kieran Milan and John Quan and Tiago Ramalho and Agnieszka Grabska-Barwinska and Demis Hassabis and Claudia Clopath and Dharshan Kumaran and Raia Hadsell},
  title         = {Overcoming catastrophic forgetting in neural networks},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1612.00796},
  primaryclass  = {cs.LG},
}

@Misc{kingma2014autoencoding,
  author        = {Diederik P Kingma and Max Welling},
  title         = {Auto-Encoding Variational Bayes},
  year          = {2014},
  archiveprefix = {arXiv},
  eprint        = {1312.6114},
  primaryclass  = {stat.ML},
}

@InProceedings{9020494,
  author    = {A. {Balatsoukas-Stimming} and C. {Studer}},
  booktitle = {2019 IEEE International Workshop on Signal Processing Systems (SiPS)},
  title     = {Deep Unfolding for Communications Systems: A Survey and Some New Directions},
  year      = {2019},
  month     = {Oct},
  pages     = {266-271},
  abstract  = {Deep unfolding is a method of growing popularity that fuses iterative optimization algorithms with tools from neural networks to efficiently solve a range of tasks in machine learning, signal and image processing, and communication systems. This survey summarizes the principle of deep unfolding and discusses its recent use for communication systems with focus on detection and precoding in multi-antenna (MIMO) wireless systems and belief propagation decoding of error-correcting codes. To showcase the efficacy and generality of deep unfolding, we describe a range of other tasks relevant to communication systems that can be solved using this emerging paradigm. We conclude the survey by outlining a list of open research problems and future research directions.},
  doi       = {10.1109/SiPS47522.2019.9020494},
  issn      = {2374-7390},
  keywords  = {belief propagation;decoding;error correction codes;iterative methods;learning (artificial intelligence);MIMO systems;optimisation;telecommunication computing;communications systems;image processing;communication systems;belief propagation decoding;machine learning;iterative optimization algorithms;neural networks;multiantenna wireless systems;MIMO;error-correcting codes;MIMO communication;Signal processing algorithms;Artificial neural networks;Precoding;Detectors;Task analysis;Machine learning;channel coding;massive MIMO;deep unfolding},
}

@Article{8766229,
  journal  = {IEEE Std 754-2019 (Revision of IEEE 754-2008)},
  title    = {IEEE Standard for Floating-Point Arithmetic},
  year     = {2019},
  month    = {July},
  pages    = {1-84},
  abstract = {This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
  doi      = {10.1109/IEEESTD.2019.8766229},
  keywords = {IEEE Standards;Floating-point arithmetic;arithmetic;binary;computer;decimal;exponent;floating-point;format;IEEE 754;interchange;NaN;number;rounding;significand;subnormal.},
}

@Online{Pascal,
  author = {NVIDIA Corporation},
  title  = {NVIDIA Tesla P100 The Most Advanced Datacenter Accelerator Ever Built},
  url    = {https://images.nvidia.com/content/pdf/tesla/whitepaper/pascal-architecture-whitepaper.pdf},
  year   = {2018},
}

@Online{Xavier,
  author = {NVIDIA Corporation},
  title  = {JETSON AGX XAVIER AND THENEW ERA OF AUTONOMOUS MACHINES},
  url    = {http://info.nvidia.com/rs/156-OFN-742/images/Jetson_AGX_Xavier_New_Era_Autonomous_Machines.pdf},
  year   = {2018},
}

@Misc{sánchez2020survey,
  author        = {José David Vega Sánchez and Luis Urquiza-Aguiar and Martha Cecilia Paredes Paredes and Diana Pamela Moya Osorio},
  title         = {Survey on Physical Layer Security for 5G Wireless Networks},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.08044},
  primaryclass  = {cs.IT},
}

@InCollection{MoyaOsorio2019,
  author = {Moya Osorio, Diana Pamela and Vega Sánchez, José and Alves, Hirley},
  title  = {Physical‐Layer Security for 5G and Beyond},
  year   = {2019},
  month  = dec,
  pages  = {1--19},
  issn   = {9781119471509},
}

@Misc{wu2018survey,
  author        = {Yongpeng Wu and Ashish Khisti and Chengshan Xiao and Giuseppe Caire and Kai-Kit Wong and Xiqi Gao},
  title         = {A Survey of Physical Layer Security Techniques for 5G Wireless Networks and Challenges Ahead},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1801.05227},
  primaryclass  = {cs.IT},
}

@Manual{nvidiatx2dev,
  title  = {NVIDIA Jetson TX2 Delivers Twice the Intelligence to the Edge},
  author = {Dustin Franklin},
  year   = {2017 (accessed September 21, 2020)},
  url    = {https://developer.nvidia.com/blog/jetson-tx2-delivers-twice-intelligence-edge/},
}

@Manual{arm,
  title = {Optimizing C Code with Neon Intrinsics - single page},
  year  = {(accessed September 21, 2020)},
  url   = {https://developer.arm.com/architectures/instruction-sets/simd-isas/neon/neon-programmers-guide-for-armv8-a/optimizing-c-code-with-neon-intrinsics/single-page},
}

@Misc{nn,
  author = {Michael Nielsen},
  title  = {How the backpropagation algorithm works},
  year   = {(accessed September 21, 2020)},
  url    = {http://neuralnetworksanddeeplearning.com/chap2.html},
}

@Comment{jabref-meta: databaseType:bibtex;}
